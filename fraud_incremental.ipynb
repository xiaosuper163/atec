{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "# import missingno as msno\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn import metrics\n",
    "# from fancyimpute import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000):\n",
    "        with pd.option_context(\"display.max_columns\", 1000):\n",
    "            display(df)\n",
    "\n",
    "def batch_save(train_x, train_y, valid_x, valid_y, test, postfix):\n",
    "    train_x.reset_index().to_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y.reset_index().to_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x.reset_index().to_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y.reset_index().to_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    test.reset_index().to_feather(\"tmp/test_{}\".format(postfix))\n",
    "    \n",
    "def batch_load(postfix):\n",
    "    train_x = pd.read_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y = pd.read_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x = pd.read_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y = pd.read_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "def my_roc(y_true, y_prob):\n",
    "    if isinstance(y_true,pd.core.series.Series):\n",
    "        y_true = np.array(y_true.tolist())\n",
    "    if isinstance(y_true,list):\n",
    "        y_true = np.array(y_true)\n",
    "    sort_index = np.argsort(y_prob)[::-1]\n",
    "    y_prob = y_prob[sort_index]\n",
    "    y_true = y_true[sort_index]\n",
    "    num_p = y_true.sum()\n",
    "    num_n = len(y_true) - num_p\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fps = []\n",
    "    tps = []\n",
    "    prob_prev = -99\n",
    "    i = 0\n",
    "    while i < len(y_true):\n",
    "        if y_prob[i]!=prob_prev:\n",
    "            fps.append(fp/num_n)\n",
    "            tps.append(tp/num_p)\n",
    "            prob_prev=y_prob[i]\n",
    "        if y_true[i]==1:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "        i+=1\n",
    "    fps.append(fp/num_n)\n",
    "    tps.append(tp/num_p)\n",
    "    return np.array(fps), np.array(tps)\n",
    "\n",
    "def my_score3(predictions, xtrain): ##Adapted from SKlearn, conservative (actual should be higher)\n",
    "    ground_truth = xtrain.get_label()\n",
    "    fpr,tpr = my_roc(ground_truth, predictions)\n",
    "#     plt.scatter(fpr, tpr)\n",
    "#     plt.show()\n",
    "    tpr1 = tpr[(fpr>=0.001).argmax()-1]\n",
    "    tpr2 = tpr[(fpr>=0.005).argmax()-1] \n",
    "    tpr3 = tpr[(fpr>=0.01).argmax()-1]\n",
    "    return 'score', 0.4 * tpr1 + 0.3 * tpr2 + 0.3* tpr3\n",
    "\n",
    "def get_ratio(predictions, xtrain):\n",
    "    ratio_predict = (predictions>0.5).sum()/predictions.shape[0]*100\n",
    "    # ratio_true = xtrain.get_label().sum()/xtrain.get_label().shape[0]*100\n",
    "    return 'score', ratio_predict\n",
    "\n",
    "def norm_standardize(df, start=0):\n",
    "    for col in df.columns[start:]:\n",
    "#         avg = df[col].mean()\n",
    "#         std = df[col].std(ddof=0)\n",
    "#         if std != 0:\n",
    "#             df[col] = (df[col]-avg)/std\n",
    "#         else:\n",
    "#             print(col)\n",
    "        a = df[col]\n",
    "        z = a\n",
    "        z[~np.isnan(a)] = zscore(a[~np.isnan(a)])\n",
    "        df[col] = z\n",
    "            \n",
    "def norm_maxmin(df, start=0):\n",
    "    for col in df.columns[start:]:\n",
    "        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "        \n",
    "def process_dates(df,date):\n",
    "    attrs = ['Day', 'Dayofweek', 'Is_month_end', 'Is_month_start']\n",
    "    for attr in attrs:\n",
    "        df[attr] = getattr(df[date].dt, attr.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = load_obj('dict_dtype')\n",
    "\n",
    "my_dict = load_obj('my_dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Load the training data and test data ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"atec_anti_fraud_train.csv\",parse_dates=['date'], dtype = dtype)\n",
    "test = pd.read_csv(\"atec_anti_fraud_test_a.csv\",parse_dates=['date'], dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_ratio = load_obj('df_missing_ratio')\n",
    "# display_all(df_missing_ratio)\n",
    "\n",
    "selected_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']<0.1].index.tolist()]\n",
    "all_nan_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']>0.9].index.tolist()]\n",
    "\n",
    "# # use the columns with no or few missing values\n",
    "# data = data.drop(all_nan_cols, axis=1)\n",
    "# test = test.drop(all_nan_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Perform one hot encoding for the columns with no more than 10 unique values ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the columns with no more than 10 unique values\n",
    "for col in data.columns[3:]:\n",
    "    data_unique = data[col].unique()\n",
    "    test_unique = test[col].unique()\n",
    "    if data_unique[~np.isnan(data_unique)].min() == test_unique[~np.isnan(test_unique)].min() and \\\n",
    "    data_unique[~np.isnan(data_unique)].max() == test_unique[~np.isnan(test_unique)].max() and \\\n",
    "    data_unique.shape[0] == test_unique.shape[0] and \\\n",
    "    data_unique.shape[0] <= 10:\n",
    "        data[col].fillna(-1.0)\n",
    "        test[col].fillna(-1.0)\n",
    "        for num in data[col].unique():\n",
    "            new_col = '{}={}'.format(col, num)\n",
    "            data[new_col] = data[col].apply(lambda x: np.isnan(x) if np.isnan(num) else x==num)\n",
    "            test[new_col] = test[col].apply(lambda x: np.isnan(x) if np.isnan(num) else x==num)\n",
    "            data.drop([col], axis=1)\n",
    "            test.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Perform normalization ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization with maxmin\n",
    "norm_maxmin(data, 3)\n",
    "norm_maxmin(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization with zscore\n",
    "norm_standardize(data, 3)\n",
    "norm_standardize(test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Sort the training data and remove the unlabeled data ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporially ignore the rows without labels\n",
    "data.sort_values('date',inplace=True)\n",
    "# unlabeled = data[data['label']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the prediction on the unlabeled training data, set the labels for unlabeled data\n",
    "data.loc[data['label']==-1,'label'] = pd.Series((pred_xgunlabeled>0.5).astype(int), name='label', index=data.loc[data['label']==-1,'label'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['label']!=-1]\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** calculate the weight of each row with trained RF model ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = load_obj('train_test_shift')\n",
    "weights = rf_model.predict_proba(data.fillna(-1).iloc[:,3:].values)[:,1:]\n",
    "\n",
    "print(weights.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from Katrina\n",
    "weights = load_obj('weights')\n",
    "\n",
    "weights.weight.values.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[weights.weight.values.argsort()[weights.shape[0]//10-weights.shape[0]:],:]\n",
    "valid = data.iloc[weights.weight.values.argsort()[:weights.shape[0]//10],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1./weights - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** data segementation based on missing pattern ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cate = pd.read_csv(\"obj/id_cate_train.csv\")\n",
    "test_cate = pd.read_csv(\"obj/id_cate_test.csv\")\n",
    "data = data.merge(train_cate, how='inner', on='id')\n",
    "test = test.merge(test_cate, how='inner', on='id')\n",
    "data = data[data['label']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = load_obj('weights')\n",
    "# weights = weights.drop('label', axis=1)\n",
    "# data = data.merge(weights, how='inner', on='id')\n",
    "\n",
    "# weights = data['weight']\n",
    "# data = data.drop('weight', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_dates(data,'date')\n",
    "test = process_dates(test,'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The way of make groups is based on the category cosine similarity analysis below\n",
    "segment_cate = [[0, 4, 9, 12, 13, 32, 33], [1, 5], [18, 31], [3, 8, 15, 17, 19, 20, 29, 32],\\\n",
    " [16, 22, 30], [7, 26], [11, 21, 23, 24, 25, 27],[2, 6, 10, 14, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = pd.DataFrame(columns=['id','score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[0])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[0])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "# train = data_seg.iloc[:len(data_seg) * 8 // 10]\n",
    "# valid = data_seg.iloc[len(data_seg) * 8 // 10:]\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "# valid_y = valid[['label']]\n",
    "# valid_x = valid.iloc[:,1:]\n",
    "\n",
    "# print(train_x.shape, valid_x.shape, train_y.shape, valid_y.shape, test_seg.shape)\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "# xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "#                       label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "# xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "#                       label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)\n",
    "# xgval = xgb.DMatrix(valid_x.values, label=valid_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 200\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)\n",
    "\n",
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "\n",
    "test_res.to_csv('pred_part_1.csv',index=False)\n",
    "\n",
    "xgb_model.save_model('model_log/multi/part1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[1])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[1])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 200\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "\n",
    "test_res.to_csv('pred_part_2.csv',index=False)\n",
    "\n",
    "xgb_model.save_model('model_log/multi/part2.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[3])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[3])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 180\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)\n",
    "\n",
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "test_res.to_csv('pred_part_4.csv',index=False)\n",
    "xgb_model.save_model('model_log/multi/part4.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[5])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[5])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.3, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 500\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)\n",
    "\n",
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "test_res.to_csv('pred_part_6.csv',index=False)\n",
    "xgb_model.save_model('model_log/multi/part6.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 6 experiment (train on the model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[5])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[5])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train = data_seg.iloc[:len(data_seg) * 8 // 10]\n",
    "valid = data_seg.iloc[len(data_seg) * 8 // 10:]\n",
    "\n",
    "train_y = train[['label']]\n",
    "train_x = train.iloc[:,1:]\n",
    "valid_y = valid[['label']]\n",
    "valid_x = valid.iloc[:,1:]\n",
    "\n",
    "# print(train_x.shape, valid_x.shape, train_y.shape, valid_y.shape, test_seg.shape)\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)\n",
    "xgval = xgb.DMatrix(valid_x.values, label=valid_y.values)\n",
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.3, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 200\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model('model_log/multi/part1.model')  # load model\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds, xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 8 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[7])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[7])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 5, 'eta': 0.3, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 300\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)\n",
    "\n",
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "test_res.to_csv('pred_part_8.csv',index=False)\n",
    "xgb_model.save_model('model_log/multi/part8.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3,5,7 (8 models in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seg = data[data['cate'].isin(segment_cate[2]+segment_cate[4]+segment_cate[6])]\n",
    "test_seg = test[test['cate'].isin(segment_cate[2]+segment_cate[4]+segment_cate[6])]\n",
    "\n",
    "data_seg = data_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "test_seg_id = test_seg.id\n",
    "test_seg_id = test_seg_id.reset_index(drop=True)\n",
    "test_seg = test_seg.drop(['id', 'cate', 'date'], axis=1)\n",
    "\n",
    "train_y = data_seg[['label']]\n",
    "train_x = data_seg.iloc[:,1:]\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "evallist = [(xgtrain, 'train')]#, (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]\n",
    "\n",
    "# set up the parameters\n",
    "params = {'max_depth': 3, 'eta': 0.2, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 60\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 666\n",
    "\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model('model_log/multi/part1.model')  # load model\n",
    "\n",
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds, xgb_model = xgb_model)\n",
    "\n",
    "xgtest = xgb.DMatrix(test_seg.values)\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "res = pd.concat([test_seg_id, pd.Series(list(preds), name='score')], axis=1)\n",
    "test_res = test_res.append(res)\n",
    "test_res.to_csv('pred_part_final.csv',index=False)\n",
    "xgb_model.save_model('model_log/multi/part357.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res=pd.read_csv('pred_part_final.csv')\n",
    "test_res=test_res.drop_duplicates(subset=['id'], keep='last')\n",
    "test_res = pd.DataFrame(test.id).merge(test_res,how='inner',on='id',indicator=True)\n",
    "test_res = test_res.drop('_merge',axis=1)\n",
    "test_res.to_csv('0021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** find the similarities between categories, put similar categories together ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_mapping = list()\n",
    "for i in range(34):\n",
    "    temp = data[data['cate']==i].head(1)\\\n",
    "        .drop(['id','label','date', 'cate', 'Day', 'Dayofweek', 'Is_month_end', 'Is_month_start'], axis=1).values[0]\n",
    "    temp_list = list()\n",
    "    for j in range(297):\n",
    "        if np.isnan(temp[j]):\n",
    "            temp_list.append(0)\n",
    "        else:\n",
    "            temp_list.append(1)\n",
    "    cate_mapping.append(tuple(temp_list))\n",
    "\n",
    "for i in range(34):\n",
    "    print('=========================')\n",
    "    temp_list = list()\n",
    "    for j in range(34):\n",
    "        if j==i:\n",
    "            temp_list.append(0)\n",
    "        else:\n",
    "            temp_list.append(cosine_similarity([list(cate_mapping[i])], [list(cate_mapping[j])])[0][0])\n",
    "    print(i, temp_list)\n",
    "    print(np.argmax(temp_list), temp_list[np.argmax(temp_list)])\n",
    "    print(np.array(temp_list).argsort()[32], temp_list[np.array(temp_list).argsort()[32]])\n",
    "    print(np.array(temp_list).argsort()[31], temp_list[np.array(temp_list).argsort()[31]])\n",
    "    print(np.array(temp_list).argsort()[30], temp_list[np.array(temp_list).argsort()[30]])\n",
    "        \n",
    "\n",
    "j = 0\n",
    "for i in range(34):\n",
    "    print('++++++++++++++++    {}    ++++++++++++++++'.format(i))\n",
    "    print(cate_mapping[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** incrementally train model ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fraction = 10\n",
    "fraction_size = data.shape[0]//10\n",
    "\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "unlabeled = []\n",
    "for i in range(num_fraction):\n",
    "    if i!=num_fraction-1:\n",
    "        data_portion = data.iloc[i*fraction_size:(i+1)*fraction_size,:]\n",
    "    else:\n",
    "        data_portion = data.iloc[i*fraction_size:,:]\n",
    "    unlabeled.append(data_portion[data_portion['label']==-1].iloc[:,3:])\n",
    "    x_batches.append(data_portion[data_portion['label']!=-1].iloc[:,3:])\n",
    "    y_batches.append(data_portion[data_portion['label']!=-1]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial model\n",
    "# set up the parameters\n",
    "params = {'max_depth': 8, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['error', 'auc']\n",
    "params[\"scale_pos_weight\"] = 5\n",
    "num_rounds = 50\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 10\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_batches[0].values, label=y_batches[0].values)\n",
    "xgb_model = xgb.train(params, xgtrain,\\\n",
    "                      num_rounds,\\\n",
    "                      [(xgtrain, 'current'),\\\n",
    "                       (xgb.DMatrix(x_batches[1].values, label=y_batches[1].values), 'next')],\\\n",
    "                      # feval=get_ratio,\\\n",
    "                      early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the unlabeled data of the first fraction\n",
    "pred_unlabeled = xgb_model.predict(xgb.DMatrix(unlabeled[0].values))\n",
    "unlabeled[0]['label'] = pd.Series((pred_unlabeled>0.5).astype(int), name='label',\\\n",
    "                                      index = unlabeled[0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incrementally train the model\n",
    "for fraction_id in range(1,num_fraction):\n",
    "    print('=========================================================================')\n",
    "    print('=====       '+str(num_fraction)+' fractions in total, training on the fraction {}'.format(fraction_id+1)+'       =====')\n",
    "    print('=========================================================================')\n",
    "#     xgtrain = xgb.DMatrix(x_batches[fraction_id].append(unlabeled[fraction_id-1].iloc[:,:-1]).values,\\\n",
    "#                           label=y_batches[fraction_id].append(unlabeled[fraction_id-1]['label']).values)\n",
    "    xgtrain = xgb.DMatrix(x_batches[fraction_id].values,\\\n",
    "                          label=y_batches[fraction_id].values)\n",
    "    if fraction_id != num_fraction-1:\n",
    "        xgb_model = xgb.train(params, xgtrain,\\\n",
    "            num_rounds,\\\n",
    "            [(xgtrain, 'current'),\\\n",
    "            (xgb.DMatrix(x_batches[fraction_id+1].values, label=y_batches[fraction_id+1].values), 'next')],\\\n",
    "            # feval=my_score3,\\\n",
    "            early_stopping_rounds=early_stopping_rounds,\\\n",
    "            xgb_model = xgb_model)\n",
    "#         pred_unlabeled = xgb_model.predict(xgb.DMatrix(unlabeled[fraction_id].values))\n",
    "#         unlabeled[fraction_id]['label'] = pd.Series((pred_unlabeled>0.5).astype(int), name='label',\\\n",
    "#                                                     index = unlabeled[fraction_id].index)\n",
    "    else:\n",
    "        num_rounds = 50\n",
    "        xgb_model = xgb.train(params, xgtrain,\\\n",
    "            num_rounds,\\\n",
    "            [(xgtrain, 'current')],\\\n",
    "            # feval=my_score3,\\\n",
    "            early_stopping_rounds=early_stopping_rounds,\\\n",
    "            xgb_model = xgb_model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Create validation set and training set ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:len(data) * 8 // 10]\n",
    "valid = data.iloc[len(data) * 8 // 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = weights.weight.values[:len(data) * 8 // 10]\n",
    "train_weights /= np.mean(train_weights) # Normalizing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['label']]\n",
    "train_x = train.iloc[:,3:]\n",
    "valid_y = valid[['label']]\n",
    "valid_x = valid.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_x.values, weight=train_weights, label=train_y.values)\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)\n",
    "xgval = xgb.DMatrix(valid_x.values,\\\n",
    "                      label=valid_y.iloc[:,:].values)\n",
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal xgtrain and xgval\n",
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)\n",
    "xgval = xgb.DMatrix(valid_x.values, label=valid_y.iloc[:,:].values)\n",
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2'), (xgval, 'val')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Train the model ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the parameters\n",
    "params = {'max_depth': 6, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['logloss', 'auc']\n",
    "params[\"colsample_bytree \"] = 0.5\n",
    "params[\"scale_pos_weight\"] = 2\n",
    "num_rounds = 300\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "#params[\"seed\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "    feval=my_score3, early_stopping_rounds=early_stopping_rounds)#, xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** save or load the model ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "xgb_model.save_model('model_log/0020.model')\n",
    "# dump model with feature map\n",
    "xgb_model.dump_model('model_log/dumpraw0020.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model('model_log/0020.model')  # load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** train the existing model on the validation set ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgval = xgb.DMatrix(valid_x.values, label=valid_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xgb_model = xgb.train(params, xgval, num_rounds, [(xgval, 'validation')], feval=my_score3, early_stopping_rounds=early_stopping_rounds, xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** predict on the testset ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_whole = pd.read_feather(\"tmp/test_native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(test.iloc[:,2:].values)\n",
    "\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "res = pd.concat([test.id, pd.Series(list(preds), name='score')], axis=1)\n",
    "\n",
    "res.to_csv(\"submission/0020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the positive ratio of the test data\n",
    "print('Ratio of positive label in unlabeled data: {}%'.format((preds>0.5).sum()/preds.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** predict on the unlabeled training set ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgunlabeled = xgb.DMatrix(unlabeled.iloc[:,3:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgunlabeled = xgb_model.predict(xgunlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the labels for the unlabeled training data\n",
    "unlabeled['label'] = pd.Series((pred_xgunlabeled>0.5).astype(int), name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([unlabeled.id, pd.Series(list(pred_xgunlabeled), name='score')], axis=1)\n",
    "res.to_csv(\"Yabin_unlabeled0011.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the positive ratio of the unlabeled data\n",
    "print('Ratio of positive label in unlabeled data: {}%'.format((pred_xgunlabeled>0.5).sum()/res.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
