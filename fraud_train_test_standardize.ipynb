{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill nas with median\n",
    "## very rude transformation of dates\n",
    "## test/train split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import missingno as msno\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "# from fancyimpute import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000):\n",
    "        with pd.option_context(\"display.max_columns\", 1000):\n",
    "            display(df)\n",
    "\n",
    "def batch_save(train_x, train_y, valid_x, valid_y, test, postfix):\n",
    "    train_x.reset_index().to_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y.reset_index().to_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x.reset_index().to_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y.reset_index().to_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    test.reset_index().to_feather(\"tmp/test_{}\".format(postfix))\n",
    "    \n",
    "def batch_load(postfix):\n",
    "    train_x = pd.read_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y = pd.read_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x = pd.read_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y = pd.read_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "def my_roc(y_true, y_prob):\n",
    "    if isinstance(y_true,pd.core.series.Series):\n",
    "        y_true = np.array(y_true.tolist())\n",
    "    if isinstance(y_true,list):\n",
    "        y_true = np.array(y_true)\n",
    "    sort_index = np.argsort(y_prob)[::-1]\n",
    "    y_prob = y_prob[sort_index]\n",
    "    y_true = y_true[sort_index]\n",
    "    num_p = y_true.sum()\n",
    "    num_n = len(y_true) - num_p\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fps = []\n",
    "    tps = []\n",
    "    prob_prev = -99\n",
    "    i = 0\n",
    "    while i < len(y_true):\n",
    "        if y_prob[i]!=prob_prev:\n",
    "            fps.append(fp/num_n)\n",
    "            tps.append(tp/num_p)\n",
    "            prob_prev=y_prob[i]\n",
    "        if y_true[i]==1:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "        i+=1\n",
    "    fps.append(fp/num_n)\n",
    "    tps.append(tp/num_p)\n",
    "    return np.array(fps), np.array(tps)\n",
    "\n",
    "def my_score3(predictions, xtrain): ##Adapted from SKlearn, conservative (actual should be higher)\n",
    "    ground_truth = y_true = xtrain.get_label()\n",
    "    fpr,tpr = my_roc(ground_truth, predictions)\n",
    "#     plt.scatter(fpr, tpr)\n",
    "#     plt.show()\n",
    "    tpr1 = tpr[(fpr>=0.001).argmax()-1]\n",
    "    tpr2 = tpr[(fpr>=0.005).argmax()-1] \n",
    "    tpr3 = tpr[(fpr>=0.01).argmax()-1]\n",
    "    return 'score', 0.4 * tpr1 + 0.3 * tpr2 + 0.3* tpr3\n",
    "\n",
    "def norm_standardize(df, start=0):\n",
    "    for col in df.columns[start:]:\n",
    "#         avg = df[col].mean()\n",
    "#         std = df[col].std(ddof=0)\n",
    "#         if std != 0:\n",
    "#             df[col] = (df[col]-avg)/std\n",
    "#         else:\n",
    "#             print(col)\n",
    "        a = df[col]\n",
    "        z = a\n",
    "        z[~np.isnan(a)] = zscore(a[~np.isnan(a)])\n",
    "        df[col] = z\n",
    "            \n",
    "def norm_maxmin(df, start=0):\n",
    "    for col in df.columns[start:]:\n",
    "        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491668,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['f3'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = load_obj('dict_dtype')\n",
    "\n",
    "my_dict = load_obj('my_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"atec_anti_fraud_train.csv\",parse_dates=['date'], dtype = dtype)\n",
    "\n",
    "test = pd.read_csv(\"atec_anti_fraud_test_a.csv\",parse_dates=['date'], dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization with maxmin\n",
    "norm_maxmin(data, 3)\n",
    "norm_maxmin(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# normalization with zscore\n",
    "norm_standardize(data, 3)\n",
    "norm_standardize(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# temporially ignore the rows without labels\n",
    "data = data[data['label']!=-1]\n",
    "\n",
    "data.sort_values('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_ratio = load_obj('df_missing_ratio')\n",
    "# display_all(df_missing_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']<0.1].index.tolist()]\n",
    "all_nan_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']>0.9].index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = []\n",
    "for col in test.columns[2:]:\n",
    "    if col not in all_nan_cols:\n",
    "        selected_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the columns with no or few missing values\n",
    "data = data[['label']+selected_cols]\n",
    "test = test[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:len(data) * 9 // 10]\n",
    "valid = data.iloc[len(data) * 9 // 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['label']]\n",
    "train_x = train.iloc[:,1:]\n",
    "valid_y = valid[['label']]\n",
    "valid_x = valid.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_x.values, label=train_y.values)\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)\n",
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the parameters\n",
    "params = {'max_depth': 8, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['auc', \"error\"]\n",
    "params[\"scale_pos_weight\"] = 5\n",
    "num_rounds = 20\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "params[\"seed\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.995502\ttrain-error:0.00889\tval_1-auc:0.978302\tval_1-error:0.014182\tval_2-auc:0.978655\tval_2-error:0.011616\ttrain-score:0.694961\tval_1-score:0.437969\tval_2-score:0.508499\n",
      "Multiple eval metrics have been passed: 'val_2-score' will be used for early stopping.\n",
      "\n",
      "Will train until val_2-score hasn't improved in 1000 rounds.\n",
      "[1]\ttrain-auc:0.995536\ttrain-error:0.008856\tval_1-auc:0.978359\tval_1-error:0.014141\tval_2-auc:0.978742\tval_2-error:0.011616\ttrain-score:0.696186\tval_1-score:0.437344\tval_2-score:0.50864\n",
      "[2]\ttrain-auc:0.995551\ttrain-error:0.008845\tval_1-auc:0.97836\tval_1-error:0.014121\tval_2-auc:0.978695\tval_2-error:0.011616\ttrain-score:0.696761\tval_1-score:0.437812\tval_2-score:0.50864\n",
      "[3]\ttrain-auc:0.995556\ttrain-error:0.008846\tval_1-auc:0.978383\tval_1-error:0.014121\tval_2-auc:0.97869\tval_2-error:0.011636\ttrain-score:0.696993\tval_1-score:0.438594\tval_2-score:0.50864\n",
      "[4]\ttrain-auc:0.995588\ttrain-error:0.008832\tval_1-auc:0.978316\tval_1-error:0.014101\tval_2-auc:0.978609\tval_2-error:0.011677\ttrain-score:0.697578\tval_1-score:0.441562\tval_2-score:0.506799\n",
      "[5]\ttrain-auc:0.995614\ttrain-error:0.008827\tval_1-auc:0.978317\tval_1-error:0.013939\tval_2-auc:0.978468\tval_2-error:0.011697\ttrain-score:0.698738\tval_1-score:0.448281\tval_2-score:0.50949\n",
      "[6]\ttrain-auc:0.995619\ttrain-error:0.008823\tval_1-auc:0.978315\tval_1-error:0.014061\tval_2-auc:0.97843\tval_2-error:0.011697\ttrain-score:0.699109\tval_1-score:0.441719\tval_2-score:0.507649\n",
      "[7]\ttrain-auc:0.995639\ttrain-error:0.00882\tval_1-auc:0.97829\tval_1-error:0.01404\tval_2-auc:0.978363\tval_2-error:0.011737\ttrain-score:0.700529\tval_1-score:0.444688\tval_2-score:0.507224\n",
      "[8]\ttrain-auc:0.99571\ttrain-error:0.00878\tval_1-auc:0.978456\tval_1-error:0.014061\tval_2-auc:0.978348\tval_2-error:0.011798\ttrain-score:0.701902\tval_1-score:0.447969\tval_2-score:0.506374\n",
      "[9]\ttrain-auc:0.995773\ttrain-error:0.008719\tval_1-auc:0.978517\tval_1-error:0.014\tval_2-auc:0.978455\tval_2-error:0.011778\ttrain-score:0.704918\tval_1-score:0.441094\tval_2-score:0.509348\n",
      "[10]\ttrain-auc:0.995781\ttrain-error:0.008713\tval_1-auc:0.97855\tval_1-error:0.014\tval_2-auc:0.978443\tval_2-error:0.011778\ttrain-score:0.705484\tval_1-score:0.445\tval_2-score:0.508499\n",
      "[11]\ttrain-auc:0.995838\ttrain-error:0.008679\tval_1-auc:0.978516\tval_1-error:0.01404\tval_2-auc:0.978516\tval_2-error:0.011737\ttrain-score:0.708129\tval_1-score:0.445625\tval_2-score:0.508357\n",
      "[12]\ttrain-auc:0.995877\ttrain-error:0.008659\tval_1-auc:0.978463\tval_1-error:0.01402\tval_2-auc:0.978431\tval_2-error:0.011717\ttrain-score:0.708751\tval_1-score:0.444375\tval_2-score:0.508782\n",
      "[13]\ttrain-auc:0.99594\ttrain-error:0.008617\tval_1-auc:0.978551\tval_1-error:0.013899\tval_2-auc:0.978433\tval_2-error:0.011717\ttrain-score:0.710644\tval_1-score:0.446094\tval_2-score:0.506657\n",
      "[14]\ttrain-auc:0.995944\ttrain-error:0.008606\tval_1-auc:0.978593\tval_1-error:0.013818\tval_2-auc:0.978472\tval_2-error:0.011717\ttrain-score:0.711266\tval_1-score:0.442031\tval_2-score:0.507649\n",
      "[15]\ttrain-auc:0.995958\ttrain-error:0.008572\tval_1-auc:0.978602\tval_1-error:0.013899\tval_2-auc:0.97853\tval_2-error:0.011737\ttrain-score:0.712064\tval_1-score:0.442656\tval_2-score:0.506374\n",
      "[16]\ttrain-auc:0.995976\ttrain-error:0.008581\tval_1-auc:0.978671\tval_1-error:0.013879\tval_2-auc:0.978705\tval_2-error:0.011757\ttrain-score:0.711711\tval_1-score:0.444531\tval_2-score:0.506799\n",
      "[17]\ttrain-auc:0.99602\ttrain-error:0.008542\tval_1-auc:0.978736\tval_1-error:0.013879\tval_2-auc:0.978718\tval_2-error:0.011757\ttrain-score:0.714022\tval_1-score:0.443125\tval_2-score:0.506657\n",
      "[18]\ttrain-auc:0.996087\ttrain-error:0.008506\tval_1-auc:0.978875\tval_1-error:0.013758\tval_2-auc:0.978638\tval_2-error:0.011697\ttrain-score:0.715655\tval_1-score:0.436875\tval_2-score:0.508074\n",
      "[19]\ttrain-auc:0.996141\ttrain-error:0.008461\tval_1-auc:0.978952\tval_1-error:0.013758\tval_2-auc:0.978752\tval_2-error:0.011717\ttrain-score:0.717307\tval_1-score:0.43875\tval_2-score:0.503683\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist, feval=my_score3, early_stopping_rounds=early_stopping_rounds, xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "xgb_model.save_model('model_log/0010.model')\n",
    "# dump model with feature map\n",
    "xgb_model.dump_model('model_log/dumpraw0010.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model('model_log/0010.model')  # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_whole = pd.read_feather(\"tmp/test_native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(test.iloc[:,:].values)\n",
    "\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "res = pd.concat([test_whole.id, pd.Series(list(preds), name='score')], axis=1)\n",
    "\n",
    "res.to_csv(\"0010.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
