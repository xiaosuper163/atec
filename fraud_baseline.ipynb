{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill nas with median\n",
    "## very rude transformation of dates\n",
    "## test/train split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import missingno as msno\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve\n",
    "# from fancyimpute import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000):\n",
    "        with pd.option_context(\"display.max_columns\", 1000):\n",
    "            display(df)\n",
    "\n",
    "def batch_save(train_x, train_y, valid_x, valid_y, test, postfix):\n",
    "    train_x.reset_index().to_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y.reset_index().to_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x.reset_index().to_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y.reset_index().to_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    test.reset_index().to_feather(\"tmp/test_{}\".format(postfix))\n",
    "    \n",
    "def batch_load(postfix):\n",
    "    train_x = pd.read_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "    train_y = pd.read_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "    valid_x = pd.read_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "    valid_y = pd.read_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "def my_roc(y_true, y_prob):\n",
    "    if isinstance(y_true,pd.core.series.Series):\n",
    "        y_true = np.array(y_true.tolist())\n",
    "    if isinstance(y_true,list):\n",
    "        y_true = np.array(y_true)\n",
    "    sort_index = np.argsort(y_prob)[::-1]\n",
    "    y_prob = y_prob[sort_index]\n",
    "    y_true = y_true[sort_index]\n",
    "    num_p = y_true.sum()\n",
    "    num_n = len(y_true) - num_p\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fps = []\n",
    "    tps = []\n",
    "    prob_prev = -99\n",
    "    i = 0\n",
    "    while i < len(y_true):\n",
    "        if y_prob[i]!=prob_prev:\n",
    "            fps.append(fp/num_n)\n",
    "            tps.append(tp/num_p)\n",
    "            prob_prev=y_prob[i]\n",
    "        if y_true[i]==1:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "        i+=1\n",
    "    fps.append(fp/num_n)\n",
    "    tps.append(tp/num_p)\n",
    "    return np.array(fps), np.array(tps)\n",
    "\n",
    "# def find_point(t, tpr, fpr):\n",
    "#     if (fpr==t).argmax()!=0:\n",
    "#         return tpr[(fpr>=t).argmax()]\n",
    "#     else:\n",
    "#         y_2 = tpr[(fpr>t).argmax()]\n",
    "#         y_1 = tpr[(fpr>t).argmax()-1]\n",
    "#         x_2 = fpr[(fpr>t).argmax()]\n",
    "#         x_1 = fpr[(fpr>t).argmax()-1]\n",
    "#         return ((y_2-y_1)*0.01-x_1*y_2+x_2*y_1)/(x_2-x_1)\n",
    "\n",
    "# def my_score1(y_prob, xtrain): ##My own version\n",
    "#     y_true = xtrain.get_label()\n",
    "#     fpr, tpr = roc_curve(y_true,y_prob)\n",
    "    \n",
    "#     # plt.scatter(fpr, tpr)\n",
    "#     # plt.show()\n",
    "    \n",
    "#     return 'score', (0.4*find_point(0.001, tpr, fpr)+0.3*find_point(0.005, tpr, fpr)+0.3*find_point(0.01, tpr, fpr))\n",
    "\n",
    "# def my_score2(y_prob, y_true): ##My own version\n",
    "#     fpr, tpr = my_roc(y_true,y_prob)\n",
    "    \n",
    "#     plt.scatter(fpr, tpr)\n",
    "#     plt.show()\n",
    "    \n",
    "#     return 'score', (0.4*find_point(0.001, tpr, fpr)+0.3*find_point(0.005, tpr, fpr)+0.3*find_point(0.01, tpr, fpr))\n",
    "\n",
    "def my_score3(predictions, xtrain): ##Adapted from SKlearn, conservative (actual should be higher)\n",
    "    ground_truth = y_true = xtrain.get_label()\n",
    "    fpr,tpr = my_roc(ground_truth, predictions)\n",
    "#     plt.scatter(fpr, tpr)\n",
    "#     plt.show()\n",
    "    tpr1 = tpr[(fpr>=0.001).argmax()-1]\n",
    "    tpr2 = tpr[(fpr>=0.005).argmax()-1] \n",
    "    tpr3 = tpr[(fpr>=0.01).argmax()-1]\n",
    "    return 'score', 0.4 * tpr1 + 0.3 * tpr2 + 0.3* tpr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = load_obj('dict_dtype')\n",
    "\n",
    "my_dict = load_obj('my_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_whole = load_obj('df_whole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array_before_filled = load_obj('array_before_filled')\n",
    "\n",
    "# filled = MICE().complete(array_before_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"atec_anti_fraud_train.csv\",parse_dates=['date'])\n",
    "# test = pd.read_csv(\"atec_anti_fraud_test_a.csv\",parse_dates=['date'])\n",
    "# df_whole = pd.concat([data.iloc[:,3:], test.iloc[:,2:]])\n",
    "# info = df_whole.describe()\n",
    "# dtype = dict()\n",
    "# null_cols = df_whole.columns[df_whole.isnull().any()].tolist()\n",
    "# for i in range(1,298):\n",
    "#     colName = 'f'+str(i)\n",
    "#     if info[colName][7]<=64:\n",
    "#         if colName not in null_cols:\n",
    "#             dtype[colName] = np.int8\n",
    "#         else:\n",
    "#             dtype[colName] = np.float16\n",
    "#     elif info[colName][7]<=32767:\n",
    "#         if colName not in null_cols:\n",
    "#             dtype[colName] = np.int16\n",
    "#         else:\n",
    "#             dtype[colName] = np.float32\n",
    "#     else:\n",
    "#         if colName not in null_cols:\n",
    "#             dtype[colName] = np.int32\n",
    "#         else:\n",
    "#             dtype[colName] = np.float64\n",
    "# save_obj(dtype, 'dict_dtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"atec_anti_fraud_train.csv\",parse_dates=['date'], dtype = dtype)\n",
    "\n",
    "test = pd.read_csv(\"atec_anti_fraud_test_a.csv\",parse_dates=['date'], dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporially ignore the rows without labels\n",
    "data = data[data['label']!=-1]\n",
    "\n",
    "data.sort_values('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_ratio = load_obj('df_missing_ratio')\n",
    "display_all(df_missing_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']<0.1].index.tolist()]\n",
    "all_nan_cols = ['f'+str(item) for item in df_missing_ratio[df_missing_ratio['positive_missing_ratio']>0.9].index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_dates(df,date):\n",
    "#     attrs = ['Day', 'Dayofweek', 'Is_month_end', 'Is_month_start']\n",
    "#     for attr in attrs:\n",
    "#         df[attr] = getattr(df[date].dt, attr.lower())\n",
    "#     return df\n",
    "# data = process_dates(data,'date')\n",
    "# test = process_dates(test,'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(train, test, col):\n",
    "    if is_numeric_dtype(train[col]):\n",
    "        if train[col].isnull().sum():\n",
    "            train[col+'_na'] = pd.isnull(train[col])\n",
    "            test[col+'_na'] = pd.isnull(test[col])\n",
    "            filler = train[col].median()\n",
    "            train[col] = train[col].fillna(filler)\n",
    "            test[col] = test[col].fillna(filler)\n",
    "    return train, test\n",
    "\n",
    "for col in data.columns:\n",
    "    data, test = fix_missing(data, test, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_train = data.shape[0]\n",
    "# num_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_y = data[['label']]\n",
    "\n",
    "# data = data.drop(['label'], axis=1)\n",
    "\n",
    "# df_whole = pd.concat([data, test])\n",
    "\n",
    "# df_whole.index = np.array([_ for _ in range(df_whole.shape[0])])\n",
    "\n",
    "# save_obj(df_whole, 'df_whole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_whole.columns:\n",
    "#     avg = df_whole[col].mean()\n",
    "#     std = df_whole[col].std()\n",
    "#     if std != 0:\n",
    "#         df_whole[col] = (df_whole[col]-avg)/std\n",
    "#     else:\n",
    "#         print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=50)\n",
    "# pca.fit(df_whole.values)\n",
    "# # save the pca model to the disk\n",
    "# save_obj(pca, 'pca50')\n",
    "# # load the pca model from the disk\n",
    "# pca = load_obj('pca50')\n",
    "# # data = data[data['label']!=-1]\n",
    "# df_whole_transformed = pd.DataFrame(pca.transform(df_whole.values), columns=['pcaFeature_{}'.format(i) for i in range(1,51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = df_whole_transformed.iloc[:num_train]\n",
    "# test = df_whole_transformed.iloc[num_train:]\n",
    "# train_x = train[data[['label']].values!=-1].iloc[:len(data) * 9 // 10]\n",
    "# valid_x = train[data[['label']].values!=-1].iloc[len(data) * 9 // 10:]\n",
    "# train_y = data[data[['label']].values!=-1][['label']].iloc[:len(data) * 9 // 10]\n",
    "# valid_y = data[data[['label']].values!=-1][['label']].iloc[len(data) * 9 // 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = data[['label']]\n",
    "# train_x = data.iloc[:,3:]\n",
    "# train_x.reset_index().to_feather(\"tmp/train_x_{}\".format('whole_native'))\n",
    "# train_y.reset_index().to_feather(\"tmp/train_y_{}\".format('whole_native'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = []\n",
    "for col in test.columns[2:]:\n",
    "    if col not in all_nan_cols:\n",
    "        selected_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the columns with no or few missing values\n",
    "data = data[['label']+selected_cols]\n",
    "test = test[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:len(data) * 9 // 10]\n",
    "valid = data.iloc[len(data) * 9 // 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('date',axis = 1, inplace=True)\n",
    "# valid.drop('date',axis = 1, inplace=True)\n",
    "\n",
    "# features = list(train.columns)[2:]\n",
    "\n",
    "train_y = train[['label']]\n",
    "train_x = train.iloc[:,1:]\n",
    "valid_y = valid[['label']]\n",
    "valid_x = valid.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_save(train_x, train_y, valid_x, valid_y, test, 'pca50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the preprocessed data from local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y = batch_load(\"native\")\n",
    "# print(train_y.label.sum(), train_y.shape)\n",
    "# print(valid_y.label.sum(), valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline prediction with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,1:].values)\n",
    "# xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,1:].values)\n",
    "\n",
    "# label_1 = valid_y.iloc[:valid_x.shape[0] // 2,:].iloc[:,1:].values\n",
    "# label_2 = valid_y.iloc[valid_x.shape[0] // 2:,:].iloc[:,1:].values\n",
    "\n",
    "# # load the model\n",
    "# xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "# xgb_model.load_model('model_log/0006.model')  # load model\n",
    "# print(my_score2(xgb_model.predict(xgval_2), label_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_x.iloc[train_x.shape[0]//2:,:].values, label=train_y.iloc[train_y.shape[0]//2:,:].values)\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,:].values)\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the parameters\n",
    "params = {'max_depth': 8, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "params['nthread'] = 4\n",
    "params['eval_metric'] = ['auc', \"error\"]\n",
    "params[\"scale_pos_weight\"] = 5\n",
    "num_rounds = 20\n",
    "early_stopping_rounds = 1000\n",
    "\n",
    "# set up the random seed for testing\n",
    "# params[\"seed\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xgb_model = xgb.train(params, xgtrain, num_rounds, evallist,\\\n",
    "                            feval=my_score3, early_stopping_rounds=early_stopping_rounds,\\\n",
    "                            xgb_model = xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the whole dataset (including training set and validation set)\n",
    "postfix = 'whole_native'\n",
    "train_x = pd.read_feather(\"tmp/train_x_{}\".format(postfix))\n",
    "train_y = pd.read_feather(\"tmp/train_y_{}\".format(postfix))\n",
    "postfix = 'native'\n",
    "valid_x = pd.read_feather(\"tmp/valid_x_{}\".format(postfix))\n",
    "valid_y = pd.read_feather(\"tmp/valid_y_{}\".format(postfix))\n",
    "xgtrain = xgb.DMatrix(train_x.iloc[:,1:].values, label=train_y.label.tolist())\n",
    "xgval_1 = xgb.DMatrix(valid_x.iloc[:valid_x.shape[0] // 2,1:].values,\\\n",
    "                      label=valid_y.iloc[:valid_x.shape[0] // 2,1:].label.tolist())\n",
    "xgval_2 = xgb.DMatrix(valid_x.iloc[valid_x.shape[0] // 2:,1:].values,\\\n",
    "                      label=valid_y.iloc[valid_x.shape[0] // 2:,1:].label.tolist())\n",
    "evallist = [(xgtrain, 'train'), (xgval_1, 'val_1'), (xgval_2, 'val_2')]\n",
    "xgb_model = xgb.train(params, xgtrain, num_rounds, evallist, feval=my_score1, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid search\n",
    "\n",
    "# max_depths = []\n",
    "# etas = []\n",
    "# scale_pos_weights = []\n",
    "# no_rounds = []\n",
    "\n",
    "# for max_depth in max_depths:\n",
    "#     for eta in etas:\n",
    "#         for scale_pos_weight in scale_pos_weights:\n",
    "#             for no_round in no_rounds:\n",
    "#                 params = {'max_depth': max_depth, 'eta': eta, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "#                 params['nthread'] = 4\n",
    "#                 params['eval_metric'] = ['auc', \"error\"]\n",
    "#                 params[\"scale_pos_weight\"] = scale_pos_weight\n",
    "#                 num_rounds = no_round\n",
    "#                 early_stopping_rounds = 120\n",
    "#                 # set up the random seed for testing\n",
    "#                 params[\"seed\"] = 6\n",
    "#                 xgb_model = xgb.train(params, xgtrain, num_rounds, evallist, feval=my_score1,\\\n",
    "#                                       early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "xgb_model.save_model('model_log/0009.model')\n",
    "# dump model with feature map\n",
    "xgb_model.dump_model('model_log/dumpraw0009.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model('model_log/0007.model')  # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_whole = pd.read_feather(\"tmp/test_native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(test.iloc[:,:].values)\n",
    "\n",
    "# make predictions\n",
    "preds = xgb_model.predict(xgtest)#, ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "res = pd.concat([test_whole.id, pd.Series(list(preds), name='score')], axis=1)\n",
    "\n",
    "res.to_csv(\"0007.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?xgb.XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,50))\n",
    "xgb.plot_importance(xgb_model, max_num_features=297, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to fill in na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_whole = pd.concat([train_x.iloc[:,1:], valid_x.iloc[:,1:], test.iloc[:,2:]])\n",
    "\n",
    "# msno.matrix(df_whole[df_whole.columns[df_whole.isnull().any()].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing columns analysis for training data\n",
    "\n",
    "data_positive = data[data['label']==1]\n",
    "data_negative = data[data['label']==0]\n",
    "data_unlabeled = data[data['label']==-1]\n",
    "\n",
    "df_missing_ratio = pd.DataFrame(columns=['positive_missing_ratio', 'negative_missing_ratio',\\\n",
    "                                        'unlabeled_missing_ratio', 'test_missing_ratio'])\n",
    "\n",
    "for col in data_positive.columns[3:]:\n",
    "    ratio_1 = data_positive[col].isnull().sum() / data_positive[col].shape[0]\n",
    "    ratio_2 = data_negative[col].isnull().sum() / data_negative[col].shape[0]\n",
    "    ratio_3 = data_unlabeled[col].isnull().sum() / data_unlabeled[col].shape[0]\n",
    "    ratio_4 = test[col].isnull().sum() / test[col].shape[0]\n",
    "    df_missing_ratio = pd.concat([df_missing_ratio,\\\n",
    "                                  pd.DataFrame(np.array([ratio_1, ratio_2, ratio_3, ratio_4]).reshape((1,4)),\\\n",
    "                                               columns = ['positive_missing_ratio', 'negative_missing_ratio',\\\n",
    "                                                          'unlabeled_missing_ratio', 'test_missing_ratio'])])\n",
    "\n",
    "df_missing_ratio.index = np.arange(1, df_missing_ratio.index.shape[0]+1)\n",
    "\n",
    "df_missing_ratio['labeled_missing_ratio'] = \\\n",
    "    (df_missing_ratio['positive_missing_ratio']*data_positive.shape[0]+df_missing_ratio['negative_missing_ratio']*data_negative.shape[0])/\\\n",
    "    (data_positive.shape[0]+data_negative.shape[0])\n",
    "\n",
    "# save_obj(df_missing_ratio, 'df_missing_ratio')\n",
    "\n",
    "display_all(df_missing_ratio)\n",
    "\n",
    "# my_dict = dict()\n",
    "# my_dict['no_missing_cols'] = selected_cols\n",
    "# my_dict['num_train'] = num_train\n",
    "# my_dict['num_test'] = num_test\n",
    "# save_obj(my_dict, 'my_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
